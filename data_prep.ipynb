{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2621465",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------\n",
    "### This notebook is used to extract and organize different kind of features that contribute to understatnding the vibe of a place\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "- Distance to Park (Distance from the current Lat, Lon tot he nearest park) --> Source: OSM Library\n",
    "- Road Density (Road infrastructure in an area, proxy for urbanization, kms/sq.km or meters/hectare) --> Source: OSM Library\n",
    "- Road Length (The total length of all roads in a buffer zone, here 500m radius) --> Source: OSM Library\n",
    "- Traffic level (Density of traffic at the corresponding time of day. Categorical - High, Low, Medium) --> Source: Tom Tom API\n",
    "- Time of day (What time of day the location is popular) --> Source: Popular Times API\n",
    "- IMD based average season temperature of the location (deg C) --> Source: IMD Python library\n",
    "- OSM Image - a raster (.png file) for the location captured by Google using regular RGB cameras --> Source: Google Places API\n",
    "- Sentinel image - an RGB satellite raster (.png ) derived from GEE at 10m for (Lat, Lon) (separate .ipynb notebook) --> Source: Copernicus Data Space Ecosystem\n",
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b758268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import osmnx.features as oxf\n",
    "from shapely.geometry import Point\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823f9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "GOOGLE_API_KEY = \"AIzaSyDI1_VxLsy9l0LsJ97K0O4UzeoKi9bxMs8\"\n",
    "TOMTOM_API_KEY = \"8PxOg8O2G3JKcECpZLNqzvlLzYWqO4VE\"\n",
    "DATA_CSV = \"vibe_search_queries_extended.csv\"\n",
    "OUTPUT_CSV = \"vibe_full_features.csv\"\n",
    "IMAGE_FOLDER = \"datasets/new_images\"\n",
    "MAX_PHOTO_WIDTH = 400\n",
    "DELAY_SEC = 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Download Google Place Photo ===\n",
    "def download_place_photo(photo_ref, folder, filename):\n",
    "    \"\"\"Downloads a Google Place photo using the photo reference and saves it locally.\n",
    "    \n",
    "    Args:\n",
    "        photo_ref (str): The Google Places API photo reference string. \n",
    "                        If None or empty, returns immediately.\n",
    "        folder (str): Directory path where the photo will be saved.\n",
    "                     Will be created if it doesn't exist.\n",
    "        filename (str): Name to give the downloaded image file \n",
    "                       (should include extension, e.g., 'photo.jpg')\n",
    "    \n",
    "    Returns:\n",
    "        str or None: The full filepath where the photo was saved if successful,\n",
    "                    or None if:\n",
    "                      - photo_ref was empty\n",
    "                      - download failed\n",
    "                      - file write failed\n",
    "    \n",
    "    Raises:\n",
    "        Prints but does not raise exceptions for:\n",
    "        - Connection errors\n",
    "        - Invalid responses\n",
    "        - File write errors\n",
    "    \n",
    "    Notes:\n",
    "        - Uses Google Places Photo API with maxwidth parameter\n",
    "        - Requires valid GOOGLE_API_KEY and MAX_PHOTO_WIDTH to be set\n",
    "        - Streams the download in 1024-byte chunks to handle large photos\n",
    "        - Creates parent directories if they don't exist\n",
    "    \"\"\"\n",
    "    if not photo_ref:\n",
    "        return None\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/photo\"\n",
    "    params = {\"photoreference\": photo_ref, \"maxwidth\": MAX_PHOTO_WIDTH, \"key\": GOOGLE_API_KEY}\n",
    "    try:\n",
    "        r = requests.get(url, params=params, stream=True)\n",
    "        if r.status_code == 200:\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                for chunk in r.iter_content(1024):\n",
    "                    f.write(chunk)\n",
    "            return filepath\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Downloading photo: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d768fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fetch Google Place Info ===\n",
    "def get_place_info(query):\n",
    "    \"\"\"Fetches place information from Google Places API using a text search query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search string to query against Google Places API\n",
    "                     (e.g., business name, address, or location)\n",
    "\n",
    "    Returns:\n",
    "        dict or None: A dictionary containing place details if successful, None if:\n",
    "                     - No results found\n",
    "                     - API request failed\n",
    "                     - Invalid response format\n",
    "                     \n",
    "        Dictionary structure:\n",
    "        {\n",
    "            \"place_name\": str,          # Name of the place\n",
    "            \"formatted_address\": str,    # Full formatted address\n",
    "            \"lat\": float,               # Latitude coordinate\n",
    "            \"lon\": float,               # Longitude coordinate  \n",
    "            \"place_id\": str,            # Google's unique place identifier\n",
    "            \"photo_reference\": str,     # Reference for retrieving photos\n",
    "            \"types\": str                # Comma-separated list of place types\n",
    "        }\n",
    "\n",
    "    Raises:\n",
    "        Prints but does not raise exceptions for:\n",
    "        - Connection errors\n",
    "        - JSON decode errors  \n",
    "        - Missing expected fields in response\n",
    "        - Invalid API responses\n",
    "\n",
    "    Notes:\n",
    "        - Requires valid GOOGLE_API_KEY to be set globally\n",
    "        - Uses Places API text search endpoint\n",
    "        - Only returns first result if multiple matches exist\n",
    "        - Missing fields will be None in returned dictionary\n",
    "        - Photo reference may be None if no photos exist\n",
    "    \"\"\"\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
    "    params = {\"query\": query, \"key\": GOOGLE_API_KEY}\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "        if \"results\" in data and len(data[\"results\"]) > 0:\n",
    "            result = data[\"results\"][0]\n",
    "            return {\n",
    "                \"place_name\": result.get(\"name\"),\n",
    "                \"formatted_address\": result.get(\"formatted_address\"),\n",
    "                \"lat\": result[\"geometry\"][\"location\"][\"lat\"],\n",
    "                \"lon\": result[\"geometry\"][\"location\"][\"lng\"],\n",
    "                \"place_id\": result.get(\"place_id\"),\n",
    "                \"photo_reference\": result.get(\"photos\", [{}])[0].get(\"photo_reference\"),\n",
    "                \"types\": \", \".join(result.get(\"types\", []))\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Place info for '{query}': {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TomTom traffic level ===\n",
    "def get_tomtom_traffic(lat, lon):\n",
    "    \"\"\"Fetches traffic level from TomTom API for given coordinates.\n",
    "    \n",
    "    Args:\n",
    "        lat (float): Latitude coordinate\n",
    "        lon (float): Longitude coordinate\n",
    "        \n",
    "    Returns:\n",
    "        str: Traffic level as one of:\n",
    "            - 'high' (speed < 40% of free flow)\n",
    "            - 'medium' (40-70% of free flow) \n",
    "            - 'low' (>=70% of free flow)\n",
    "            - 'unknown' if API fails or data missing\n",
    "            \n",
    "    Note:\n",
    "        Requires TOMTOM_API_KEY to be set globally\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = \"https://api.tomtom.com/traffic/services/4/flowSegmentData/relative0/10/json\"\n",
    "        params = {'point': f\"{lat},{lon}\", 'key': TOMTOM_API_KEY}\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json().get('flowSegmentData', {})\n",
    "        speed = data.get('currentSpeed')\n",
    "        free_flow = data.get('freeFlowSpeed')\n",
    "        if speed and free_flow:\n",
    "            if speed < 0.4 * free_flow:\n",
    "                return 'high'\n",
    "            elif speed < 0.7 * free_flow:\n",
    "                return 'medium'\n",
    "            else:\n",
    "                return 'low'\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] TomTom for ({lat},{lon}): {e}\")\n",
    "    return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dde999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Google Popular Times ===\n",
    "def get_populartimes_from_google(lat, lon, category=\"cafe\", radius=0.01):\n",
    "    \"\"\"Fetches popular times data from Google for nearby places of given category.\n",
    "    \n",
    "    Args:\n",
    "        lat (float): Center point latitude\n",
    "        lon (float): Center point longitude\n",
    "        category (str): Place category to search (default: \"cafe\")\n",
    "        radius (float): Search radius in degrees (default: 0.01 ~ 1km)\n",
    "        \n",
    "    Returns:\n",
    "        list: List of popular times data dictionaries if found, None otherwise\n",
    "        \n",
    "    Note:\n",
    "        Requires populartimes library and Google API access\n",
    "    \"\"\"\n",
    "    bounds = (lat - radius, lon - radius, lat + radius, lon + radius)\n",
    "    try:\n",
    "        import populartimes\n",
    "        results = populartimes.get(\"com.google.android.maps\", [category], bounds, 3)\n",
    "        for r in results:\n",
    "            if 'populartimes' in r:\n",
    "                return r['populartimes']\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Populartimes for ({lat},{lon}): {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Create vibe folders ===\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "vibe_classes = df[\"vibe_class\"].unique()\n",
    "for vibe in vibe_classes:\n",
    "    os.makedirs(os.path.join(IMAGE_FOLDER, vibe), exist_ok=True)\n",
    "\n",
    "# === OSM Features for Bangalore ===\n",
    "city = \"Bangalore, India\"\n",
    "gdf_parks = oxf.features_from_place(city, tags={'leisure': 'park'}).to_crs(epsg=4326)\n",
    "G = ox.graph_from_place(city, network_type='drive')\n",
    "gdf_roads = ox.graph_to_gdfs(G)[0].to_crs(epsg=4326)\n",
    "proj_crs = \"EPSG:32643\"\n",
    "gdf_parks_proj = gdf_parks.to_crs(proj_crs)\n",
    "gdf_roads_proj = gdf_roads.to_crs(proj_crs)\n",
    "\n",
    "# === Main loop ===\n",
    "features = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    query, vibe = row[\"query\"], row[\"vibe_class\"]\n",
    "    info = get_place_info(query)\n",
    "    if not info:\n",
    "        continue\n",
    "\n",
    "    lat, lon = info[\"lat\"], info[\"lon\"]\n",
    "    folder = os.path.join(IMAGE_FOLDER, vibe)\n",
    "    filename = f\"{vibe}_{idx}.jpg\"\n",
    "    image_path = download_place_photo(info[\"photo_reference\"], folder, filename)\n",
    "\n",
    "    # Distance to nearest park\n",
    "    point = Point(lon, lat)\n",
    "    dist_to_park = gdf_parks.distance(point).min() * 111000 if len(gdf_parks) > 0 else None\n",
    "\n",
    "    # Road density\n",
    "    gdf_point = gpd.GeoSeries([point], crs=\"EPSG:4326\").to_crs(proj_crs)\n",
    "    buffer = gdf_point.buffer(500).iloc[0]\n",
    "    roads_near = gdf_roads_proj[gdf_roads_proj.intersects(buffer)]\n",
    "    road_density = len(roads_near)\n",
    "    road_length = roads_near.length.sum()\n",
    "\n",
    "    # Traffic & Time of Day\n",
    "    traffic_level = get_tomtom_traffic(lat, lon)\n",
    "    pop_data = get_populartimes_from_google(lat, lon)\n",
    "    if pop_data:\n",
    "        max_hour = [max(d['data']) for d in pop_data if 'data' in d]\n",
    "        time_of_day = sum(max_hour) / len(max_hour) if max_hour else random.choice([\"morning\", \"afternoon\", \"evening\", \"night\"])\n",
    "    else:\n",
    "        time_of_day = random.choice([\"morning\", \"afternoon\", \"evening\", \"night\"])\n",
    "\n",
    "    features.append({\n",
    "        \"query\": query,\n",
    "        \"place_name\": info[\"place_name\"],\n",
    "        \"formatted_address\": info[\"formatted_address\"],\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon,\n",
    "        \"vibe_class\": vibe,\n",
    "        \"place_id\": info[\"place_id\"],\n",
    "        \"photo_reference\": info[\"photo_reference\"],\n",
    "        \"types\": info[\"types\"],\n",
    "        \"image_path\": image_path if image_path else \"NA\",\n",
    "        \"dist_to_park\": dist_to_park,\n",
    "        \"road_density\": road_density,\n",
    "        \"road_length\": road_length,\n",
    "        \"traffic_level\": traffic_level,\n",
    "        \"populartimes_peak_avg\": time_of_day\n",
    "    })\n",
    "\n",
    "    time.sleep(DELAY_SEC)\n",
    "\n",
    "# === Save all combined features ===\n",
    "pd.DataFrame(features).to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"All features saved to: {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8154f34e",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------\n",
    "### To download imd weather data (Temperature) for each Lat, Lon\n",
    "-----------------------------------------------------------------------------------------------------\n",
    "- Hit IMD server using imdlib pip library \n",
    "- Needs start and end date and the Lat, Lon\n",
    "- Obtains the temporal composite, avg seasonal temperature at that location\n",
    "------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imdlib as imd\n",
    "import xarray as xr\n",
    "\n",
    "# Step 1: Read CSV\n",
    "df = pd.read_csv(rf\"D:\\vibe_place_mapper\\vibe_full_features_with_scraped_new_updated.csv\")  # must contain 'lat' and 'lon' columns\n",
    "\n",
    "# Step 2: Get IMD data for tmin and tmax\n",
    "start_dy = '2024-03-01'\n",
    "end_dy = '2024-06-01'\n",
    "file_dir = '../data'\n",
    "\n",
    "var_data = {}\n",
    "for var in ['tmin', 'tmax']:\n",
    "    data = imd.get_real_data(var, start_dy, end_dy, file_dir)\n",
    "    ds = data.get_xarray()\n",
    "    ds = ds.where(ds[var] != 99.90000153)\n",
    "    var_data[var] = ds[var]  # Save cleaned DataArray\n",
    "\n",
    "# Step 3: Loop through CSV and compute tmean\n",
    "avg_temps = []\n",
    "for _, row in df.iterrows():\n",
    "    lat = row['lat']\n",
    "    lon = row['lon']\n",
    "    \n",
    "    # Get tmin and tmax time series at this location\n",
    "    tmin_point = var_data['tmin'].sel(lat=lat, lon=lon, method='nearest')\n",
    "    tmax_point = var_data['tmax'].sel(lat=lat, lon=lon, method='nearest')\n",
    "    \n",
    "    # Compute tmean time series\n",
    "    tmean = (tmin_point + tmax_point) / 2\n",
    "    \n",
    "    # Compute mean tmean over time\n",
    "    mean_temp = tmean.mean().item()  # Convert to Python float\n",
    "    avg_temps.append(mean_temp)\n",
    "\n",
    "# Step 4: Save back to CSV\n",
    "df['avg_temperature'] = avg_temps\n",
    "df.to_csv(rf\"D:\\vibe_place_mapper\\vibe_full_features_with_scraped_new_updated_temp.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vibe_map",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
